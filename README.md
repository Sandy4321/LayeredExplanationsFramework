# Layered Explanations Framework

Layered Explanations Framework aims to exploit the intrinsic architecture of neural networks, namely hidden units, to generate an interpretable explanation of the algorithmic decision. It consists of 3 main steps:

1. Identify the greatest-explanatory layer and
2. Influential units using numerical influence measures, then we
3. Reconstruct relevant input regions responsible for activating these influential units.

![Layered Explantions Framwork](img\framework.png "Layered Explantions Framwork")

## Documents 

Interesting readers can find more details in following documents:
- 